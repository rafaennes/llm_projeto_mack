# Chat SQL com Mistral - Transpar√™ncia Governamental

Cliente Streamlit inteligente que converte perguntas em linguagem natural para queries SQL usando Mistral 7B.

**Baseado no padr√£o NSC (Natural SQL Chatbot)**

## üéØ Como Funciona

```
Pergunta em Linguagem Natural
         ‚Üì
   Mistral 7B analisa + Knowledge Base
         ‚Üì
     Gera SQL automaticamente
         ‚Üì
  Executa no banco SQLite
         ‚Üì
 Exibe resultados em tabela
         ‚Üì
 Gera resposta em linguagem natural
```

## ‚ú® Funcionalidades

### 1. **Convers√£o NL ‚Üí SQL com IA**
- Usa Mistral 7B local para entender perguntas complexas
- Knowledge base integrada com schema completo
- Regras de neg√≥cio e exemplos de queries

### 2. **Exibi√ß√£o Completa**
- ‚úÖ **SQL Gerado**: Mostra a query constru√≠da
- ‚úÖ **Tabela de Resultados**: Dados formatados
- ‚úÖ **Resposta Natural**: An√°lise em portugu√™s
- ‚úÖ **Valores Formatados**: R$ 1.500.000,00

### 3. **Hist√≥rico de Conversa**
- Todas perguntas e respostas salvas na sess√£o
- SQL de cada consulta dispon√≠vel para confer√™ncia
- Bot√£o para limpar hist√≥rico

## üöÄ In√≠cio R√°pido

### 1. Inicie o chat

```bash
cd /home/ennes/mestrado/llm_projeto
./mcp_client/start_chat.sh
```

### 2. Aguarde o carregamento

‚è≥ **Primeira execu√ß√£o**: ~30-60 segundos (Mistral carregando)
‚ö° **Pr√≥ximas**: Instant√¢neo (modelo fica em cache)

### 3. Acesse e pergunte!

Abra http://localhost:8504 e fa√ßa perguntas como:

```
Quais os 10 parlamentares que mais receberam recursos?
```

```
Mostre emendas para S√£o Paulo acima de 1 milh√£o
```

```
Compare o total de emendas entre as regi√µes
```

## üí¨ Exemplos de Perguntas

### An√°lises Gerais
- "Quais os 10 parlamentares que mais receberam recursos?"
- "Mostre a distribui√ß√£o de emendas por regi√£o"
- "Qual o total de valores pagos por ano?"
- "Compare gastos entre Sudeste e Nordeste"

### Buscas Espec√≠ficas
- "Busque emendas para S√£o Paulo"
- "Emendas do deputado Silva em 2023"
- "Emendas de sa√∫de acima de 1 milh√£o"
- "Mostre emendas para educa√ß√£o no Rio de Janeiro"

### Agrega√ß√µes e Estat√≠sticas
- "Qual a m√©dia de valor por emenda?"
- "Total investido em educa√ß√£o por estado"
- "Quantas emendas foram pagas em 2022?"
- "Qual o maior valor pago em uma √∫nica emenda?"

## üìä O Que Voc√™ Ver√°

Para cada pergunta, o sistema mostra:

### 1. **SQL Gerado** (expans√≠vel)
```sql
SELECT nome_autor, SUM(valor_pago) as total_pago
FROM emendas_parlamentares
GROUP BY nome_autor
ORDER BY total_pago DESC
LIMIT 10
```

### 2. **Tabela de Resultados**
| nome_autor | total_pago |
|------------|------------|
| Jo√£o Silva | R$ 5.000.000,00 |
| Maria Santos | R$ 4.500.000,00 |
| ... | ... |

### 3. **An√°lise em Linguagem Natural**
> **An√°lise:** Foram encontrados 10 parlamentares. Jo√£o Silva lidera com R$ 5 milh√µes em emendas pagas, seguido por Maria Santos com R$ 4,5 milh√µes. Os 10 parlamentares somam R$ 35 milh√µes em recursos.

## üß† Knowledge Base

O sistema usa uma base de conhecimento integrada que cont√©m:

### Schema Completo
- 19 colunas da tabela `emendas_parlamentares`
- Tipos de dados de cada coluna
- Descri√ß√µes e exemplos

### Regras de Neg√≥cio
- Hierarquia de valores (empenhado ‚Üí liquidado ‚Üí pago)
- Geografia (regi√µes, UFs, munic√≠pios)
- Classifica√ß√£o or√ßament√°ria
- Vocabul√°rio comum (tradu√ß√µes)

### Exemplos de Queries
- Top N parlamentares
- Buscas por munic√≠pio
- Distribui√ß√£o por regi√£o
- Filtros por fun√ß√£o or√ßament√°ria

**Arquivo**: [knowledge_base.py](knowledge_base.py)

## üîß Arquitetura

### Componentes

```python
# 1. Knowledge Base (knowledge_base.py)
- Schema da tabela
- Regras de neg√≥cio
- Exemplos de queries
- Prompts para o LLM

# 2. Chat App (chat_app.py)
- Interface Streamlit
- Carregamento do Mistral
- Convers√£o NL ‚Üí SQL
- Execu√ß√£o de queries
- Gera√ß√£o de respostas
```

### Fluxo de Dados

```
Usu√°rio: "Top 10 autores"
    ‚Üì
[Knowledge Base] + [Pergunta]
    ‚Üì
[Mistral LLM] ‚Üí Gera SQL
    ‚Üì
"SELECT nome_autor, SUM(valor_pago)..."
    ‚Üì
[SQLite] ‚Üí Executa query
    ‚Üì
DataFrame com resultados
    ‚Üì
[Mistral LLM] ‚Üí Gera resposta natural
    ‚Üì
"Foram encontrados 10 parlamentares..."
```

## üÜö Compara√ß√£o com Vers√£o Anterior

| Caracter√≠stica | Vers√£o Simples | **Vers√£o com Mistral** |
|---------------|----------------|------------------------|
| **NL ‚Üí SQL** | Regras if/else | ‚úÖ Mistral 7B |
| **Intelig√™ncia** | B√°sica (keywords) | ‚úÖ Alta (entende contexto) |
| **Respostas** | Apenas dados | ‚úÖ Dados + an√°lise natural |
| **SQL vis√≠vel** | ‚ùå N√£o | ‚úÖ Sim (expans√≠vel) |
| **Formata√ß√£o** | B√°sica | ‚úÖ Moeda brasileira |
| **Knowledge** | Nenhum | ‚úÖ Schema + regras |
| **Carregamento** | Instant√¢neo | ‚è≥ 30-60s (primeira vez) |

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente

O script `start_chat.sh` configura automaticamente:

```bash
DB_SQL_URL="sqlite:///.../db_transparencia.db"
LLM_PATH=".../mistral-7b-instruct-v0.2.gguf"
```

### Par√¢metros do Mistral

```python
LlamaCpp(
    model_path=LLM_PATH,
    temperature=0.1,      # Baixa = mais determin√≠stico
    max_tokens=2048,      # M√°ximo de tokens na resposta
    n_ctx=4096,          # Context window
    n_gpu_layers=0,      # CPU only (0) ou GPU (>0)
    verbose=False
)
```

## üêõ Troubleshooting

### Erro: "Modelo LLM n√£o encontrado"
```bash
# Verifique se o modelo existe
ls -lh llm_models/mistral-7b-instruct-v0.2.gguf

# Deve ter ~4.1GB
```

### Erro: "ModuleNotFoundError: langchain_community"
```bash
source venv/bin/activate
pip install langchain==0.1.20 langchain-community==0.0.38
```

### Mistral demora muito para carregar
- Normal na primeira vez: 30-60 segundos
- Nas pr√≥ximas: Cache do Streamlit reutiliza
- Se usar GPU (n_gpu_layers > 0): Mais r√°pido

### SQL gerado est√° errado
1. Verifique o prompt em [knowledge_base.py](knowledge_base.py)
2. Ajuste a temperatura (0.0 = mais determin√≠stico)
3. Adicione mais exemplos no knowledge base

### Tabela n√£o aparece
- Verifique se a query retornou resultados
- Veja o SQL gerado (clique no expansor)
- Teste a query direto no SQLite

## üìà Performance

### Tempos T√≠picos

| Opera√ß√£o | Tempo |
|----------|-------|
| Carregar Mistral (primeira vez) | 30-60s |
| Carregar Mistral (cache) | <1s |
| NL ‚Üí SQL | 2-5s |
| Executar SQL | <1s |
| Gerar resposta natural | 2-5s |
| **Total por pergunta** | **4-10s** |

### Otimiza√ß√µes

- ‚úÖ Streamlit `@st.cache_resource` no LLM
- ‚úÖ Temperature baixa (0.1) para respostas r√°pidas
- ‚úÖ Limite de tokens (2048)
- ‚úÖ SQL com LIMIT autom√°tico

## üîí Seguran√ßa

- ‚úÖ Apenas queries SELECT permitidas
- ‚úÖ Valida√ß√£o antes de executar SQL
- ‚úÖ Limite de 100 resultados por query
- ‚úÖ Timeout de execu√ß√£o
- ‚ö†Ô∏è Para produ√ß√£o: adicionar autentica√ß√£o

## üéì Baseado em NSC

Este cliente segue o padr√£o **NSC (Natural SQL Chatbot)**:

1. ‚úÖ Knowledge base com schema
2. ‚úÖ Convers√£o NL ‚Üí SQL com LLM
3. ‚úÖ Execu√ß√£o segura de queries
4. ‚úÖ Exibi√ß√£o de SQL para confer√™ncia
5. ‚úÖ Tabela de resultados formatada
6. ‚úÖ Resposta em linguagem natural

## üìù Pr√≥ximos Passos

### Melhorias Planejadas

- [ ] Suporte a gr√°ficos (matplotlib/plotly)
- [ ] Exportar resultados (CSV, Excel, PDF)
- [ ] Hist√≥rico persistente (banco de dados)
- [ ] Sugest√µes de perguntas baseadas no contexto
- [ ] Multi-tabelas (joins autom√°ticos)
- [ ] Cache de queries frequentes
- [ ] Logs de analytics

### Integra√ß√µes Futuras

- [ ] RAG com MongoDB (documentos legais)
- [ ] APIs em tempo real
- [ ] Notifica√ß√µes de novas emendas
- [ ] Compara√ß√µes temporais autom√°ticas

## üìö Arquivos

```
mcp_client/
‚îú‚îÄ‚îÄ chat_app.py           # Interface Streamlit principal
‚îú‚îÄ‚îÄ knowledge_base.py     # Schema + regras + prompts
‚îú‚îÄ‚îÄ start_chat.sh         # Script de inicializa√ß√£o
‚îî‚îÄ‚îÄ README.md             # Esta documenta√ß√£o
```

## ü§ù Contribuindo

Para adicionar novas funcionalidades:

### 1. Melhorar Knowledge Base
Edite `knowledge_base.py` ‚Üí `DATABASE_SCHEMA`

### 2. Adicionar Valida√ß√µes
Edite `chat_app.py` ‚Üí `execute_sql()`

### 3. Customizar Prompts
Edite `knowledge_base.py` ‚Üí `get_sql_generation_prompt()`

## üìÑ Licen√ßa

MIT License - Projeto acad√™mico de mestrado

---

**Desenvolvido para:** An√°lise de Transpar√™ncia Governamental
**Tecnologias:** Mistral 7B, Streamlit, SQLite, LangChain
**Dados:** 87.912 emendas parlamentares do Governo Federal
